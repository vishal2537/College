{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]   #to create an identity matrix of shape(num_classes, num_classes)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    sum_exp_z = np.sum(exp_z, axis=0)\n",
    "    softmax_probs = exp_z / sum_exp_z\n",
    "    return softmax_probs\n",
    "\n",
    "\n",
    "def initialize_parameters(dim):\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, y):\n",
    "    m = X.shape[1]\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    epsilon = 1e-8  # A small constant to avoid division by zero\n",
    "    cost = (-1/m) * np.sum(y * np.log(A + epsilon) +(1 - y) * np.log(1 - A + epsilon))\n",
    "    dw = (1/m) * np.dot(X, (A - y).T)\n",
    "    db = (1/m) * np.sum(A - y)\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, y, num_iterations, learning_rate):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "    params = {\"w\": w, \"b\": b}\n",
    "    return params, costs\n",
    "\n",
    "def predict(w, b, X):\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "accuracy of 0 : 0.9629629629629629\n",
      "accuracy of 1 : 0.7407407407407407\n",
      "accuracy of 2 : 0.9259259259259259\n",
      "accuracy of 3 : 0.8888888888888888\n",
      "accuracy of 4 : 0.9259259259259259\n",
      "Best Fold: 0 & Accuracy: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5,random_state=None)\n",
    "print(kf)\n",
    "\n",
    "accuracies = []\n",
    "best_accuracy = 0\n",
    "best_fold = 0\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    models = []\n",
    "\n",
    "    for class_label in np.unique(y_train_fold):\n",
    "        y_binary = (y_train_fold == class_label).astype(int)\n",
    "        w, b = initialize_parameters(X_train_fold.shape[1])\n",
    "        num_iterations = 10000\n",
    "        learning_rate = 0.06\n",
    "        params, _ = optimize(w, b, X_train_fold.T, y_binary.reshape(1, -1), num_iterations, learning_rate)\n",
    "        models.append(params)\n",
    "\n",
    "    z_values = np.zeros((len(models), X_test_fold.shape[0]))\n",
    "    for i, params in enumerate(models):\n",
    "        w, b = params[\"w\"], params[\"b\"]\n",
    "        z_values[i] = np.dot(w.T, X_test_fold.T) + b\n",
    "\n",
    "    class_probabilities = softmax(z_values)\n",
    "    predictions = np.argmax(class_probabilities, axis=0)\n",
    "    accuracy = (predictions == y_test_fold).mean()\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"accuracy of {fold} : {accuracy}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_fold = fold\n",
    "        \n",
    "print(f\"Best Fold: {best_fold} & Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
